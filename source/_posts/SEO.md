---
title: 前端有利于SEO的操作总结
layout: post
date: 2022-01-18 14:20
comments: true
tags: 
	- SEO
  - SSR
  - HTML/JavaScript/CSS
key: "1"
---

### 简介

> 相信大家对 SEO 并不陌生吧，全称（Sarch Engine Optimize）搜索引擎优化，SEO 是随着搜索引擎的出现而来的，两者是相互促进，互利共生的关系。SEO 的存在就是为了提升网页在搜索引擎自然搜索结果中的收录数量以及排序位置而做的优化行为。而优化的目的就是为了提升网站在搜索引擎中的权重，增加对搜索引擎的友好度，使得用户在访问网站时能排在前面。

<!--more-->
### 搜索引擎工作原理
> 在搜索引擎网站的后台会有一个非常庞大的数据库，里面存储了海量的关键词，而每个关键词又对应着很多网址，这些网址是被称之为“搜索引擎蜘蛛”或“网络爬虫”程序从互联网上收集而来的。

### 分类

- **白帽 SEO：** 起到了改良和规范网站设计的作用，使网站对搜索引擎和用户更加友好，并且网站也能从搜索引擎中获取合理的流量，这是搜索引擎鼓励和支持的。
- **黑帽 SEO：** 利用和放大搜索引擎政策缺陷来获取更多用户的访问量，这类行为大多是欺骗搜索引擎，一般搜索引擎公司是不支持与鼓励的。

### 为何要做 SEO

> 提高网站的权重，增强搜索引擎友好度，以达到提高排名，增加流量，改善（潜在）用户体验，促进销售的作用。

### 前端 SEO 规范

> 前端是构建网站中很重要的一个环节，前端的工作主要是负责页面的 HTML+CSS+JS，优化好这几个方面会为 SEO 工作打好一个坚实的基础。通过网站的结构布局设计和网页代码优化，使前端页面既能让浏览器用户能够看懂（提升用户体验），也能让“蜘蛛”看懂（提高搜索引擎友好度）。

### 关于 SEO 需要注意的事项

#### 1、网站结构布局优化：尽量简单、开门见山，提倡扁平化结构

- 控制首页链接数量
  > 网站首页是权重最高的地方，如果首页链接太少，没有“桥”，“蜘蛛”不能继续往下爬到内页，直接影响网站收录数量。但是首页链接也不能太多，一旦太多，没有实质性的链接，很容易影响用户体验，也会降低网站首页的权重，收录效果也不好。
- 扁平化目录层次
  > 尽量让“蜘蛛”只要跳转 3 次，就能到达网站内的任何一个内页。
- 导航优化
  > 导航应该尽量采用文字方式，也可以搭配图片导航，但是图片代码一定要进行优化，标签必须添加“alt”和“title”属性，告诉搜索引擎导航的定位，做到即使图片未能正常显示时，用户也能看到提示文字。
  > 在每一个网页上应该加上面包屑导航，好处：帮助用户很快了解网站组织形式，从而形成更好的位置感，同时提供了返回各个页面的接口，方便用户操作；对“蜘蛛”而言，能够清楚的了解网站结构，同时还增加了大量的内部链接，方便抓取，降低跳出率。
- 网站的结构布局---不可忽略的细节
  - 页面头部：logo 及主导航，以及用户的信息。
  - 页面主体：左边正文，包括面包屑导航及正文；右边放热门文章及相关文章，好处：留住访客，让访客多停留，对“蜘蛛”而言，这些文章属于相关链接，增强了页面相关性，也能增强页面的权重。
  - 页面底部：版权信息和友情链接。
- 利用布局，把重要内容 HTML 代码放在最前
- 控制页面的大小，减少 http 请求，提高网站的加载速度

#### 2、网页代码优化

- 突出重要内容---合理的设计 title、description 和 keywords

- 语义化书写 HTML 代码，符合 W3C 标准

- 标签：页内链接，要加 “title” 属性加以说明，让访客和 “蜘蛛” 知道。而外部链接，链接到其他网站的，则需要加上 el="nofollow" 属性, 告诉 “蜘蛛” 不要爬，因为一旦“蜘蛛”爬了外部链接之后，就不会再回来了。

  ```javascript
  <a href="https://www.360.cn" title="360安全中心" class="logo"></a>
  ```

- 利用 <img> 中的 alt 属性

    > alt 属性可以在图片未成功显示时候，使用文本来代替图片的呈现，使“爬虫”可以抓取到这个信息。此外它还可以解决浏览器禁用图像或屏幕阅读器解析等问题。
- 设置 rel='nofollow' 忽略跟踪

    > 如果某个 `<a>` 的链接不需要跟踪，那么添加 rel='nofollow' 即可通知“爬虫”忽略跟踪。因为“爬虫”分配到每个页面的权重是一定的，为了集中网页权重并将权重分给其他必要的链接，为不必跟踪的链接添加这个属性就显得很必要了。
- 提高加载速度

    > 尽量让结构（HTML）、表现（CSS）及行为（JavaScript）三者分离。如果在一个 HTML 页面中，编写大量的 CSS 样式或脚本，会拖慢其加载速度，此外，如果不为 `<img>` 定义宽高，那么会引起页面重新渲染，同样也会影响加载速度。一旦加载超时，“爬虫”就会放弃爬取。

#### 3、服务端渲染SSR
  > 定义：是指在服务端完成页面的html 拼接处理， 然后再发送给浏览器，将不具有交互能力的html结构绑定事件和状态，在客户端展示为具有完整交互能力的应用程序。
  ##### 适用场景

  - 需要更好的支持SEO

      > 优势在于同步。搜索引擎爬虫是不会等待异步请求数据结束后再抓取信息的，如果 SEO 对应用程序至关重要，但你的页面又是异步请求数据，那 SSR 可以帮助你很好的解决这个问题。

  - 需要更快的到达时间

      >  优势在于慢网络和运行缓慢的设备场景。传统 SPA 需完整的 JS 下载完成才可执行，而SSR 服务器渲染标记在服务端渲染 html 后即可显示，用户会更快的看到首屏渲染页面。如果首屏渲染时间转化率对应用程序至关重要，那可以使用 SSR 来优化。

  ##### 优点

  - 更快的响应时间，不用等待所有的JS都下载完成，浏览器便能显示比较完整的页面了
  - 更好的SSR，我们可以将SEO的关键信息直接在后台就渲染成HTML，而保证搜索引擎的爬虫都能爬取到关键数据。
  
  ##### 缺点

  - 相对于仅仅需要提供静态文件的服务器，SSR中使用的渲染程序自然会占用更多的CPU和内存资源
  - 一些常用的浏览器API可能无法正常使用，比如window、docment和alert等，如果使用的话需要对运行的环境加以判断
  - 开发调试会有一些麻烦，因为涉及了浏览器及服务器，对于SPA的一些组件的生命周期的管理会变得复杂
  - 可能会由于某些因素导致服务器端渲染的结果与浏览器端的结果不一致
### 结束语

> 前面主要从结构与布局层面粗略的讲了一些利于 SEO 的操作。当然远不止这些，如有想到其他的欢迎留言探讨，感谢各位读者的支持。